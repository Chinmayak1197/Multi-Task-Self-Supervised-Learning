{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyNFIfl36kCR"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "kYorJcI-Bnpz",
        "outputId": "cfa069a6-fc29-4d03-8656-8773031aaa48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-8c960cb32a6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# inputs, labels = inputs.cuda(), labels.cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MyModel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "def cbr_layer(in_channels, out_channels, kernel_size, groups=1, stride=1, activation=True):\n",
        "    if activation:\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=int(kernel_size / 2),\n",
        "                      groups=groups, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU6(inplace=True))\n",
        "    else:\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=int(kernel_size / 2),\n",
        "                      groups=groups,\n",
        "                      bias=False),\n",
        "            nn.BatchNorm2d(out_channels, affine=True, eps=1e-5, momentum=0.1))\n",
        "\n",
        "\n",
        "class InvertedResidualBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, exp, stride):\n",
        "        super().__init__()\n",
        "        intermed_planes = in_planes*exp\n",
        "        self.residual = (in_planes == out_planes) and (stride == 1)\n",
        "        self.output = nn.Sequential(cbr_layer(in_planes, intermed_planes, kernel_size=1),\n",
        "                                     cbr_layer(intermed_planes, intermed_planes, kernel_size=3, stride=stride, groups=intermed_planes),\n",
        "                                     cbr_layer(intermed_planes, out_planes, kernel_size=1, activation=False))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.output(x)\n",
        "        if self.residual:\n",
        "            return (out+x)\n",
        "        else:\n",
        "            return out\n",
        "\n",
        "class Mobilenet_backbone(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        mobilenet_config = [[1, 16, 1, 1],\n",
        "                            [6, 24, 2, 2],\n",
        "                            [6, 32, 3, 2],\n",
        "                            [6, 64, 4, 2],\n",
        "                            [6, 96, 3, 1],\n",
        "                            [6, 160, 3, 2],\n",
        "                            [6, 320, 1, 1]]\n",
        "\n",
        "        self.in_channels = 32\n",
        "        self.layer1 = cbr_layer(3, self.in_channels, kernel_size=3, stride=2)\n",
        "        layer_count = 2\n",
        "        for t, c, n, s in mobilenet_config:\n",
        "            layers = []\n",
        "            for i in range(n):\n",
        "                layers.append(InvertedResidualBlock(self.in_channels, c, t, stride=s if i==0 else 1))\n",
        "                self.in_channels = c\n",
        "            setattr(self, \"layer{}\".format(layer_count), nn.Sequential(*layers))\n",
        "            layer_count += 1\n",
        "\n",
        "    def forward(self,x):\n",
        "        l1 = self.layer1(x)\n",
        "        l2 = self.layer2(l1)\n",
        "        l3 = self.layer3(l2)  # 24, x / 4\n",
        "        l4 = self.layer4(l3)  # 32, x / 8\n",
        "        l5 = self.layer5(l4)  # 64, x / 16\n",
        "        l6 = self.layer6(l5)  # 96, x / 16\n",
        "        l7 = self.layer7(l6)  # 160, x / 32\n",
        "        l8 = self.layer8(l7)  # 320, x / 32\n",
        "\n",
        "        return l3, l4, l5, l6, l7, l8\n",
        "class CRPBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, num_stages, groups=False):\n",
        "        super().__init__()\n",
        "        for i in range(num_stages):\n",
        "            setattr(self, '{}_{}'.format(i+1, 'outvar_dimred'),\n",
        "                    nn.Conv2d(in_planes if (i == 0) else out_planes,\n",
        "                              out_planes, kernel_size=1, stride=1,\n",
        "                              padding=0, bias=False, groups=in_planes if groups else 1))\n",
        "        self.stride = 1\n",
        "        self.n_stages = num_stages\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=5, stride=1, padding=2)\n",
        "\n",
        "    def forward(self,x):\n",
        "        out=x\n",
        "        for i in range(self.n_stages):\n",
        "            out = self.maxpool(out)\n",
        "            out = getattr(self, '{}_{}'.format(i+1, 'outvar_dimred'))(out)\n",
        "            x = out+x\n",
        "        return x\n",
        "\n",
        "class RefineNetDecoder(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.conv8 = nn.Conv2d(320, 256, kernel_size=1, stride=1, padding=0, groups=1, bias=False)\n",
        "        self.conv7 = nn.Conv2d(160, 256, kernel_size=1, stride=1, padding=0, groups=1, bias=False)\n",
        "        self.conv6 = nn.Conv2d(96, 256, kernel_size=1, stride=1, padding=0, groups=1, bias=False)\n",
        "        self.conv5 = nn.Conv2d(64, 256, kernel_size=1, stride=1, padding=0, groups=1, bias=False)\n",
        "        self.conv4 = nn.Conv2d(32, 256, kernel_size=1, stride=1, padding=0, groups=1, bias=False)\n",
        "        self.conv3 = nn.Conv2d(24, 256, kernel_size=1, stride=1, padding=0, groups=1, bias=False)\n",
        "        self.crp4 = self.make_crp(256, 256, 4, groups=False)\n",
        "        self.crp3 = self.make_crp(256, 256, 4, groups=False)\n",
        "        self.crp2 = self.make_crp(256, 256, 4, groups=False)\n",
        "        self.crp1 = self.make_crp(256, 256, 4, groups=True)\n",
        "        self.conv_adapt4 = nn.Conv2d(256, 256, kernel_size=1, stride=1, padding=0, groups=1, bias=False)\n",
        "        self.conv_adapt3 = nn.Conv2d(256, 256, kernel_size=1, stride=1, padding=0, groups=1, bias=False)\n",
        "        self.conv_adapt2 = nn.Conv2d(256, 256, kernel_size=1, stride=1, padding=0, groups=1, bias=False)\n",
        "        self.relu = nn.ReLU6(inplace=True)\n",
        "        self.pre_depth = nn.Conv2d(256, 256, kernel_size=1, stride=1, padding=0, groups=256, bias=False)\n",
        "        self.depth = nn.Conv2d(256, 1, kernel_size=3, stride=1, padding=1, dilation=1, groups=1, bias=True)\n",
        "        self.pre_segm = nn.Conv2d(256, 256, kernel_size=1, stride=1, padding=0, groups=256, bias=False)\n",
        "        self.segm = nn.Conv2d(256, self.num_classes, kernel_size=3, stride=1, padding=1, dilation=1, groups=1, bias=True)\n",
        "\n",
        "    def make_crp(self, in_planes, out_planes, num_stages, groups=False):\n",
        "        layers = [CRPBlock(in_planes, out_planes, num_stages, groups=groups)]\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, l3, l4, l5, l6, l7, l8):\n",
        "        l8 = self.conv8(l8)\n",
        "        l7 = self.conv7(l7)\n",
        "        l7 = self.relu(l8+l7)\n",
        "        l7 = self.crp4(l7)\n",
        "        l7 = self.conv_adapt4(l7)\n",
        "        l7 = nn.Upsample(size = l6.size()[2:],mode='bilinear', align_corners=False)(l7)\n",
        "\n",
        "        l6 = self.conv6(l6)\n",
        "        l5 = self.conv5(l5)\n",
        "        l5 = self.relu(l5+l6+l7)\n",
        "        l5 = self.crp3(l5)\n",
        "        l5 = self.conv_adapt3(l5)\n",
        "        l5 = nn.Upsample(size = l4.size()[2:],mode='bilinear', align_corners=False)(l5)\n",
        "        l4 = self.conv4(l4)\n",
        "        l4 = self.relu(l5+l4)\n",
        "        l4 = self.crp2(l4)\n",
        "        l4 = self.conv_adapt2(l4)\n",
        "        l4 = nn.Upsample(size = l3.size()[2:],mode='bilinear', align_corners=False)(l4)\n",
        "\n",
        "        l3 = self.conv3(l3)\n",
        "        l3 = self.relu(l3+l4)\n",
        "        l3 = self.crp1(l3)\n",
        "\n",
        "        out_segm = self.pre_segm(l3)\n",
        "        out_segm = self.relu(out_segm)\n",
        "        out_segm = self.segm(out_segm)\n",
        "\n",
        "        out_depth = self.pre_depth(l3)\n",
        "        out_depth = self.relu(out_depth)\n",
        "        out_depth = self.depth(out_depth)\n",
        "\n",
        "        return out_depth, out_segm\n",
        "\n",
        "\n",
        "class Hydranet(nn.Module):\n",
        "    def __init__(self, num_tasks, num_classes):\n",
        "        super().__init__()\n",
        "        self.n_classes = num_classes\n",
        "        self.n_tasks = num_tasks\n",
        "        self.enc = Mobilenet_backbone()\n",
        "        self.dec = RefineNetDecoder(self.n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        l3, l4, l5, l6, l7, l8 = self.enc(x)\n",
        "        out_depth, out_segm = self.dec(l3, l4, l5, l6, l7, l8)\n",
        "        return out_depth, out_segm"
      ],
      "metadata": {
        "id": "aZr-MFhQ9wti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "48khuam19w4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1FrFm-zJwCLP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ecd02c3-984a-421b-aa88-ef7a1e29d2fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.colors as co\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "#from Hydranet import Hydranet\n",
        "\n",
        "\n",
        "hydranet = Hydranet(2,6)\n",
        "ckpt = torch.load(\"/content/ExpKITTI_joint.ckpt\", map_location='cpu')\n",
        "hydranet.enc.load_state_dict(ckpt[\"state_dict\"], strict=False)\n",
        "hydranet.dec.load_state_dict(ckpt[\"state_dict\"], strict=False)\n",
        "hydranet.eval()\n",
        "\n",
        "IMG_SCALE  = 1./255\n",
        "IMG_MEAN = np.array([0.485, 0.456, 0.406]).reshape((1, 1, 3))\n",
        "IMG_STD = np.array([0.229, 0.224, 0.225]).reshape((1, 1, 3))\n",
        "CMAP = np.load('/content/cmap_nyud.npy')\n",
        "NUM_CLASSES = 6\n",
        "\n",
        "\n",
        "def prepare_img(img):\n",
        "    return (img * IMG_SCALE - IMG_MEAN) / IMG_STD\n",
        "\n",
        "\n",
        "def pipeline(img):\n",
        "    with torch.no_grad():\n",
        "        img_var = Variable(torch.from_numpy(prepare_img(img).transpose(2,0,1)[None]), requires_grad=False).float()\n",
        "        if torch.cuda.is_available():\n",
        "            img_var = img_var.cuda()\n",
        "        depth, segm = hydranet(img_var)\n",
        "        segm = cv2.resize(segm[0].cpu().data.numpy().transpose(1,2,0), img.shape[:2][::-1], interpolation=cv2.INTER_CUBIC)\n",
        "        depth = cv2.resize(depth[0].cpu().data.numpy().transpose(1,2,0), img.shape[:2][::-1], interpolation=cv2.INTER_CUBIC)\n",
        "        segm = CMAP[segm.argmax(axis=2)].astype(np.uint8)\n",
        "        depth = np.abs(depth).astype(np.uint8)\n",
        "        return depth, segm\n",
        "\n",
        "def project_to_image(img, depth, seg):\n",
        "    cmap_proj = plt.cm.get_cmap(\"hsv\", 256)\n",
        "    cmap_proj = np.array([cmap_proj(i) for i in range(256)])[:, :3] * 255\n",
        "    img_copy = cv2.addWeighted(img, 0.8, seg, 1.5, 0.7)\n",
        "    for i in range(depth.shape[0]):\n",
        "        for j in range(depth.shape[1]):\n",
        "            num = np.random.randint(1, 20)\n",
        "            num1 = np.random.randint(1, 20)\n",
        "            if i>100 and (j%num==0 or i%num1==0) and depth[i][j]>5:\n",
        "                if num<8:\n",
        "                    continue\n",
        "                point_depth = depth[i][j]\n",
        "                color = cmap_proj[int(510/point_depth),:]\n",
        "                cv2.circle(img_copy, (j,i), 2, tuple(color), thickness=-1)\n",
        "    return img_copy\n",
        "\n",
        "def depth_to_rgb(depth):\n",
        "    normalizer = co.Normalize(vmin=0, vmax=80)\n",
        "    mapper = cm.ScalarMappable(norm=normalizer, cmap='plasma')\n",
        "    colormapped_im = (mapper.to_rgba(depth)[:, :, :3] * 255).astype(np.uint8)\n",
        "    return colormapped_im\n",
        "\n",
        "video_files = sorted(glob.glob(\"demo/*.png\"))\n",
        "result_video = []\n",
        "projected_video = []\n",
        "count=0\n",
        "for idx, img_path in enumerate(video_files):\n",
        "    image = np.array(Image.open(img_path))\n",
        "    h, w, _ = image.shape\n",
        "    depth, seg = pipeline(image)\n",
        "    projected_output = project_to_image(image, depth, seg)\n",
        "    result_video.append(cv2.cvtColor(cv2.vconcat([image, seg, depth_to_rgb(depth)]), cv2.COLOR_BGR2RGB))\n",
        "    projected_video.append(cv2.cvtColor(projected_output, cv2.COLOR_BGR2RGB))\n",
        "    count+=1\n",
        "\n",
        "out = cv2.VideoWriter('/content/out.mp4',cv2.VideoWriter_fourcc(*'MP4V'), 15, (w,3*h))\n",
        "proj = cv2.VideoWriter('/content/proj.mp4', cv2.VideoWriter_fourcc(*'MP4V'), 15, (w,h))\n",
        "\n",
        "for i in range(len(result_video)):\n",
        "    out.write(result_video[i])\n",
        "out.release()\n",
        "\n",
        "\n",
        "for i in range(len(projected_video)):\n",
        "    proj.write(projected_video[i])\n",
        "proj.release()"
      ],
      "metadata": {
        "id": "Nki5Sai66_Fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FYgWVo8Z9tVa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}